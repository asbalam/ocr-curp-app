# app.py

# üß± Importamos las librer√≠as necesarias para construir el microservicio
from flask import Flask, request, jsonify         # Para crear la API y manejar las solicitudes/respuestas
from flask_cors import CORS                       # Para permitir peticiones desde otros dominios (como APEX)
import openai                                     # Cliente oficial de OpenAI para conectarse con su API
import base64                                     # Para codificar archivos en base64 (necesario para enviar im√°genes)
import os                                         # Para acceder a variables del sistema (como la API Key)
from pdf2image import convert_from_bytes          # Para convertir archivos PDF a im√°genes
from io import BytesIO                            # Para manipular archivos en memoria como si fueran archivos reales
from PIL import Image                             # Librer√≠a para trabajar con im√°genes (aunque aqu√≠ no editamos)
import re                                         # Para limpiar texto con expresiones regulares
import json                                       # Para convertir respuestas en formato JSON

# üöÄ Inicializamos la app Flask
app = Flask(__name__)
CORS(app)  # Habilitamos CORS para aceptar llamadas desde otros or√≠genes (como apex.oracle.com)

# üîê Cargamos la clave de la API de OpenAI desde una variable de entorno
openai.api_key = os.getenv("OPENAI_API_KEY")

# üìå Ruta principal de la API
@app.route('/ocr-curp', methods=['POST'])
def ocr_curp():
    # Verificamos que se haya enviado un archivo
    if 'file' not in request.files:
        return jsonify({"error": "No se envi√≥ un archivo"}), 400

    file = request.files['file']
    content_type = file.content_type  # Obtenemos el tipo MIME (ej: image/jpeg o application/pdf)
    images_base64 = []  # Lista para guardar im√°genes codificadas en base64

    try:
        if content_type == "application/pdf":
            # Si es PDF, convertimos la primera p√°gina a imagen JPEG
            pages = convert_from_bytes(file.read())  # Convierte a lista de p√°ginas (im√°genes)
            img_io = BytesIO()
            pages[0].save(img_io, format="JPEG")     # Guardamos la primera p√°gina en formato JPEG
            img_data = base64.b64encode(img_io.getvalue()).decode("utf-8")  # Convertimos a base64
            images_base64.append(img_data)
        else:
            # Si es imagen (JPG o PNG), simplemente la codificamos
            img_data = base64.b64encode(file.read()).decode("utf-8")
            images_base64.append(img_data)
    except Exception as e:
        # Error al procesar el archivo (formato no compatible, da√±ado, etc.)
        return jsonify({"error": f"Error procesando archivo: {str(e)}"}), 500

    # üß† Instrucci√≥n que se le enviar√° a OpenIA para extraer los datos del CURP
    content = [
        {
        "type": "text",
        "text": (
            "Este es un documento de datos personales. Extrae los campos y responde "
            "solo con un JSON plano, sin comillas triples ni texto adicional. El formato es:\n\n"
            "{\n"
            "  \"nombre\": \"\",\n"
            "  \"apellido_paterno\": \"\",\n"
            "  \"apellido_materno\": \"\",\n"
            "  \"fecha\": \"DD/MM/YYYY\",\n"
            "  \"calle_y_numero\": \"\",\n"
            "  \"colonia\": \"\",\n"
            "  \"ciudad_municipio\": \"\",\n"
            "  \"estado\": \"\",\n"
            "  \"codigo_postal\": \"\",\n"
            "  \"pais_nacimiento\": \"\",\n"
            "  \"nacionalidad\": \"\",\n"
            "  \"fecha_nacimiento\": \"DD/MM/YYYY\",\n"
            "  \"rfc\": \"\",\n"
            "  \"correo_electronico\": \"\",\n"
            "  \"telefono\": \"\",\n"
            "  \"ocupacion\": \"\",\n"
            "  \"origen_recursos\": \"\",\n"
            "  \"ha_desempenado_cargo_en_gobierno\": \"S√≠\" o \"No\"\n"
            "}"
        )
        }
    ]

    # Agregamos cada imagen (convertida o enviada) como parte del mensaje
    for img in images_base64:
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{img}"
            }
        })

    try:
        # Llamamos a la API de OpenAI usando el modelo GPT-4o
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": content}],
            max_tokens=300
        )

        # Tomamos el texto generado por GPT y lo limpiamos
        raw_result = response.choices[0].message.content.strip()

        # Eliminamos posibles comillas triples ```json que podr√≠an venir en la respuesta
        cleaned = re.sub(r"^```json|```$", "", raw_result.strip(), flags=re.MULTILINE).strip()

        # Convertimos el texto limpio a JSON (verifica que sea un formato v√°lido)
        parsed = json.loads(cleaned)

        # Devolvemos el JSON como respuesta al cliente
        return jsonify(parsed)

    except json.JSONDecodeError as e:
        # Si el modelo devolvi√≥ un JSON mal formado, avisamos con el contenido original
        return jsonify({
            "error": "Respuesta JSON inv√°lida",
            "detalle": str(e),
            "raw": raw_result
        }), 500
    except Exception as e:
        # Otro tipo de errores (fallo en la API, conexi√≥n, etc.)
        return jsonify({"error": str(e)}), 500

# üñ•Ô∏è Ejecutamos el servidor localmente solo si corremos el script directamente
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

